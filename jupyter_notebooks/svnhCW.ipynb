{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3e245b",
   "metadata": {},
   "source": [
    "Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, gdown\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Input, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad42b0",
   "metadata": {},
   "source": [
    "NumPy Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for NumPy’s pseudo random number generator so its the same for the whole run\n",
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b50887",
   "metadata": {},
   "source": [
    "Downloading & Loading the SVHN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46432de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ensure cache dir exists\n",
    "cache_dir = \"/tmp/svhn_data\"\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "# download both train and test .mat files from google drive\n",
    "gdown.download(\"https://drive.google.com/uc?id=1FSwCLJzPzL4ZmihRgjIkh3DImRwM0UHb\",\n",
    "               os.path.join(cache_dir, \"train_32x32.mat\"), quiet=False)\n",
    "gdown.download(\"https://drive.google.com/uc?id=10E7i5m1HaGWZkte4P8WMouNoFj0dFHmv\",\n",
    "               os.path.join(cache_dir, \"test_32x32.mat\"), quiet=False)\n",
    "\n",
    "# load into memory\n",
    "train_raw = loadmat(os.path.join(cache_dir, \"train_32x32.mat\"))\n",
    "test_raw  = loadmat(os.path.join(cache_dir, \"test_32x32.mat\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcfcd42",
   "metadata": {},
   "source": [
    "Load Images & Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image data into NumPy arrays\n",
    "train_images = np.array(train_raw['X'])\n",
    "test_images = np.array(test_raw['X'])\n",
    "\n",
    "# Extract corresponding label arrays\n",
    "train_labels = train_raw['y']\n",
    "test_labels = test_raw['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6132a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original shape from .mat: (height, width, channels, num_images)\n",
    "# Keras expects: (num_images, height, width, channels)\n",
    "# So we move the last axis (–1) to the front (0)\n",
    "train_images = np.moveaxis(train_images, -1, 0)  # (N, 32, 32, 3)\n",
    "test_images  = np.moveaxis(test_images,  -1, 0)  # (M, 32, 32, 3)\n",
    "\n",
    "# Print to verify: now (num_samples, height, width, channels)\n",
    "print(\"Train images shape:\", train_images.shape)\n",
    "print(\"Test  images shape:\", test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b983aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a random image and its label\n",
    "plt.imshow(train_images[13529])\n",
    "plt.show()\n",
    "\n",
    "print('Label: ', train_labels[13529])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede41b5",
   "metadata": {},
   "source": [
    "Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast image arrays to float64 to retain precision in operations like normalization\n",
    "train_images = train_images.astype('float64')\n",
    "test_images  = test_images.astype('float64')\n",
    "\n",
    "# Cast label arrays to int64 so they’re recognized as integer classes by ML tools\n",
    "train_labels = train_labels.astype('int64')\n",
    "test_labels  = test_labels.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ec997",
   "metadata": {},
   "source": [
    "Normalize Pixel Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c71be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before scaling, check pixel intensity range, should be 0–255\n",
    "print(f\"Min: {train_images.min()}, Max: {train_images.max()}\")\n",
    "\n",
    "# Scale all pixels to [0, 1] – this helps the network train faster\n",
    "train_images /= 255.0\n",
    "test_images  /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173f6437",
   "metadata": {},
   "source": [
    "Remap 10 Labels to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba8def",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In the SVHN dataset, the digit “0” is encoded as label 10.\n",
    "We need to convert these to 0 so that labels run 0–9 as usual.\n",
    "\"\"\"\n",
    "\n",
    "# Replace all occurrences of 10 with 0 in both train and test label arrays\n",
    "train_labels[train_labels == 10] = 0\n",
    "test_labels[test_labels == 10]   = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bb32b7",
   "metadata": {},
   "source": [
    "One-Hot Encoder Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3eed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize one-hot encoder\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# Fit to training labels and convert to one-hot vectors\n",
    "train_labels = lb.fit_transform(train_labels)\n",
    "\n",
    "# Convert test labels using the fitted encoder\n",
    "test_labels = lb.transform(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15653e",
   "metadata": {},
   "source": [
    "Split into Train & Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4000 samples was the maximum samples that could be selected due to memory issues in the github workspace\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images[:4000], train_labels[:4000],\n",
    "                                                  test_size=0.15, random_state=22)\n",
    "# Hold out 15% for validation and used a fixed seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48cee3c",
   "metadata": {},
   "source": [
    "Data Augmentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932125f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data augmenter with common transforms\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=8,         # rotate images up to ±8°\n",
    "    zoom_range=[0.95, 1.05],  # zoom in/out by up to 5%\n",
    "    height_shift_range=0.10,  # shift vertically by up to 10% of image height\n",
    "    shear_range=0.15          # apply shear transformations up to 15%\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before training: set up a list + callback to log the LR\n",
    "lrs = []\n",
    "\n",
    "class LRTLogger(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # grab the current learning rate from the optimizer and append it\n",
    "        lr = float(keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        lrs.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da6d5f6",
   "metadata": {},
   "source": [
    "Define the Auxiliary CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset any existing Keras state (clear old layers, optimizers, etc.)\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Build a sequential model block by block\n",
    "aux_model = keras.Sequential([\n",
    "    # Block 1: two 32-filter conv layers, then downsample\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "           input_shape=(32, 32, 3)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Block 2: two 64-filter conv layers, then downsample\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Block 3: two 128-filter conv layers, then downsample\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Global pooling replaces Flatten to cut activations drastically\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    # Smaller dense head to further reduce parameters\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    # Final classification layer (10 classes, softmax)\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Learning rate schedule: 1e-4 × 10^(epoch/10)\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-4 * 10**(epoch / 10)\n",
    ")\n",
    "\n",
    "# Adam optimizer with AMSGrad variant\n",
    "optimizer = Adam(learning_rate=1e-4, amsgrad=True)\n",
    "\n",
    "# Compile model with categorical crossentropy and accuracy metric\n",
    "aux_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
    "              lambda epoch: 1e-4 * 10**(epoch / 10))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4, amsgrad=True)\n",
    "aux_model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145edbd2",
   "metadata": {},
   "source": [
    "Train Auxiliary Model for LR Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5609a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our callback to log the LR after each epoch\n",
    "lr_logger = LRTLogger()\n",
    "\n",
    "# Begin training\n",
    "history = aux_model.fit(\n",
    "    # Use our ImageDataGenerator for on-the-fly augmentation\n",
    "    datagen.flow(X_train, y_train, batch_size=128),\n",
    "    \n",
    "    epochs=30,                 # Train for 30 epochs to sweep learning rates\n",
    "    validation_data=(X_val, y_val),  # Evaluate on held-out validation set\n",
    "    \n",
    "    # Apply the LR schedule and record the actual LR values\n",
    "    callbacks=[lr_schedule, lr_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b558a",
   "metadata": {},
   "source": [
    "Plot LR vs Loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292838ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss against learning rate \n",
    "plt.semilogx(lrs, history.history['loss'])\n",
    "# Define plot range: x from min→max LR, y from 0→max loss\n",
    "plt.axis([min(lrs), max(lrs), 0, max(history.history['loss'])])\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Learning Rate vs. Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f09046",
   "metadata": {},
   "source": [
    "Define the Main CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb8bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any previous Keras state\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Build the sequential CNN\n",
    "model = keras.Sequential([\n",
    "    # Conv block 1: 32 filters\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "           input_shape=(32, 32, 3)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Conv block 2: 64 filters\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Conv block 3: 128 filters\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Reduce spatial dims via global average pooling\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    # Dense head with 32 units\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    # Output layer: 10 classes with softmax\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Callback: stop training if val_loss doesn't improve for 8 epochs\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=8)\n",
    "\n",
    "# Optimizer: Adam with a higher learning rate\n",
    "optimizer = Adam(learning_rate=1e-3, amsgrad=True)\n",
    "\n",
    "# Callback: save only the best model to disk\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    \"best_cnn.keras\", save_best_only=True\n",
    ")\n",
    "\n",
    "# Compile the model with categorical crossentropy and accuracy metric\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cfa7ec",
   "metadata": {},
   "source": [
    "Showing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36744477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model as a table below\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba86a730",
   "metadata": {},
   "source": [
    "Train the Main Model for Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ba9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on augmented data, with early stopping and best‐model checkpointing\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=128),  # augmented training batches\n",
    "    epochs=60,                                       # train up to 60 epochs\n",
    "    validation_data=(X_val, y_val),                  # evaluate on validation set\n",
    "    callbacks=[early_stopping, model_checkpoint]     # stop early and save best weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67f240c",
   "metadata": {},
   "source": [
    "Extract Training & Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2804812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate train and validation accuracies and losses\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6ad0f",
   "metadata": {},
   "source": [
    "Plot the Training and Validation accuracys and losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbfcfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize epochs vs. train and validation accuracies and losses\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Epochs vs. Training and Validation Accuracy')\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Epochs vs. Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c77fe",
   "metadata": {},
   "source": [
    "Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39459883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate in batches of 16 samples as memory is low\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    x=test_images,\n",
    "    y=test_labels,\n",
    "    batch_size=16,  \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test loss:     {test_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67921874",
   "metadata": {},
   "source": [
    "Generate Predictions & Decode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f2850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and apply inverse transformation to the labels\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "# Convert one-hot training labels back to integers\n",
    "y_pred = lb.inverse_transform(y_pred, lb.classes_)\n",
    "y_train = lb.inverse_transform(y_train, lb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd7e75f",
   "metadata": {},
   "source": [
    "Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d05321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute confusion matrix for training set\n",
    "matrix = confusion_matrix(y_train, y_pred, labels=lb.classes_)\n",
    "\n",
    "# plot as heatmap\n",
    "fig, ax = plt.subplots(figsize=(14,12))\n",
    "sns.heatmap(matrix, annot=True, cmap='Greens', fmt='d', ax=ax)\n",
    "ax.set(title='Confusion Matrix for Training Dataset',\n",
    "       xlabel='Predicted label',\n",
    "       ylabel='True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c34f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the errors in the plots\n",
    "\n",
    "np.seterr(all='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63455d48",
   "metadata": {},
   "source": [
    "Build an Activation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfcc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all your conv layers\n",
    "conv_layers   = [l for l in model.layers if isinstance(l, Conv2D)]\n",
    "layer_outputs = [l.output for l in conv_layers]\n",
    "\n",
    "# Grab the input tensor from the very first layer\n",
    "input_tensor = model.layers[0].input\n",
    "\n",
    "# Build your activation model\n",
    "activation_model = Model(inputs=input_tensor, outputs=layer_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81f780",
   "metadata": {},
   "source": [
    "Function that plots the convolutional filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59058904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function which will plot the convolutional filters\n",
    "\n",
    "def plot_convolutional_filters(img):\n",
    "    # Add a batch dimension: (height, width, channels) → (1, h, w, c)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Run the activation model to get feature maps from each conv layer\n",
    "    activations = activation_model.predict(img)\n",
    "\n",
    "    # Number of filter activations to display per row\n",
    "    images_per_row = 9\n",
    "\n",
    "    # Loop over each layer’s activations\n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        # Total number of filters in this layer\n",
    "        n_features = layer_activation.shape[-1]\n",
    "        # Spatial size of each feature map (height = width)\n",
    "        size = layer_activation.shape[1]\n",
    "        # Number of rows needed in our display grid\n",
    "        n_cols = n_features // images_per_row\n",
    "\n",
    "        # Prepare a grid to hold all the filter images\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "        # Populate the grid with each filter’s activation map\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                # Extract the activation of one filter\n",
    "                channel_image = layer_activation[\n",
    "                    0,               # first (and only) image in batch\n",
    "                    :,               # all rows\n",
    "                    :,               # all cols\n",
    "                    col * images_per_row + row  # specific filter index\n",
    "                ]\n",
    "\n",
    "                # Normalize the activation for better contrast\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= (channel_image.std() + 1e-5)\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "\n",
    "                # Place the processed image into the display grid\n",
    "                display_grid[\n",
    "                    col * size : (col + 1) * size,\n",
    "                    row * size : (row + 1) * size\n",
    "                ] = channel_image\n",
    "\n",
    "        # Plot the grid for this layer\n",
    "        scale = 1.0 / size\n",
    "        plt.figure(figsize=(\n",
    "            scale * display_grid.shape[1],\n",
    "            scale * display_grid.shape[0]\n",
    "        ))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b015b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train.shape:\", X_train.shape)\n",
    "# selecting what image to show\n",
    "img = X_train[41]\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba986c96",
   "metadata": {},
   "source": [
    "Plotting with the convolutional filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fa77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convolutional_filters(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a059ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
