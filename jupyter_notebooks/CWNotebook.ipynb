{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Flattern' from 'tensorflow.keras.layers' (/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/_tf_keras/keras/layers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical, plot_model\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Conv2D, MaxPool2D, Flattern, Dropout\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Earlystopping\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Flattern' from 'tensorflow.keras.layers' (/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/_tf_keras/keras/layers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# If you prefer consistency under tensorflow.keras, do:\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_CPP_MIN_LOG_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# tf will show error messages only\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_style(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # tf will show error messages only\n",
    "sns.set_style('White')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "train_raw = loadmat('../input/svhndataset/train_32x32.mat')\n",
    "test_raw = loadmat('../input/svhndataset/test_32x32.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels\n",
    "\n",
    "train_images = np.array(train_raw['X'])\n",
    "test_images = np.array(test_raw['X'])\n",
    "\n",
    "train_labels = train_raw['y']\n",
    "test_labels = test_raw['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the data\n",
    "\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the axes of the images\n",
    "\n",
    "train_images = np.moveaxis(train_images, -1, 0)\n",
    "test_images = np.moveaxis(test_images, -1, 0)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a random image and its label\n",
    "\n",
    "plt.imshow(train_images[13529])\n",
    "plt.show()\n",
    "\n",
    "print('Label: ', train_labels[13529])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and test images into 'float64' type\n",
    "\n",
    "train_images = train_images.astype('float64')\n",
    "test_images = test_images.astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and test labels into 'int64' type\n",
    "\n",
    "train_labels = train_labels.astype('int64')\n",
    "test_labels = test_labels.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images data\n",
    "\n",
    "print('Min: {}, Max: {}'.format(train_images.min(), train_images.max()))\n",
    "\n",
    "train_images /= 255.0\n",
    "test_images /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding of train and test labels\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "train_labels = lb.fit_transform(train_labels)\n",
    "test_labels = lb.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train data into train and validation sets\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels,\n",
    "                                                  test_size=0.15, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=8,\n",
    "                             zoom_range=[0.95, 1.05],\n",
    "                             height_shift_range=0.10,\n",
    "                             shear_range=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define auxillary model\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "aux_model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), padding='same', \n",
    "                           activation='relu',\n",
    "                           input_shape=(32, 32, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, (3, 3), padding='same', \n",
    "                        activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3, 3), padding='same', \n",
    "                           activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, (3, 3), padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3, 3), padding='same', \n",
    "                           activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, (3, 3), padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.4),    \n",
    "    keras.layers.Dense(10,  activation='softmax')\n",
    "])\n",
    "\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
    "              lambda epoch: 1e-4 * 10**(epoch / 10))\n",
    "optimizer = keras.optimizers.Adam(lr=1e-4, amsgrad=True)\n",
    "aux_model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model in order to determine best learning rate\n",
    "\n",
    "history = aux_model.fit_generator(datagen.flow(X_train, y_train, batch_size=128),\n",
    "                              epochs=30, validation_data=(X_val, y_val),\n",
    "                              callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Learning Rate vs. Loss\n",
    "\n",
    "plt.semilogx(history.history['lr'], history.history['loss'])\n",
    "plt.axis([1e-4, 1e-1, 0, 4])\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define actual model\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), padding='same', \n",
    "                           activation='relu',\n",
    "                           input_shape=(32, 32, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, (3, 3), padding='same', \n",
    "                        activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3, 3), padding='same', \n",
    "                           activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, (3, 3), padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3, 3), padding='same', \n",
    "                           activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, (3, 3), padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.4),    \n",
    "    keras.layers.Dense(10,  activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=8)\n",
    "optimizer = keras.optimizers.Adam(lr=1e-3, amsgrad=True)\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                   '/kaggle/working/best_cnn.h5', \n",
    "                   save_best_only=True)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model in order to make predictions\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=128),\n",
    "                              epochs=70, validation_data=(X_val, y_val),\n",
    "                              callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate train and validation accuracies and losses\n",
    "\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize epochs vs. train and validation accuracies and losses\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Epochs vs. Training and Validation Accuracy')\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Epochs vs. Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test data\n",
    "test_loss, test_acc = model.evaluate(x=test_images, y=test_labels, verbose=0)\n",
    "\n",
    "print('Test accuracy is: {:0.4f} \\nTest loss is: {:0.4f}'.\n",
    "      format(test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and apply inverse transformation to the labels\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "y_pred = lb.inverse_transform(y_pred, lb.classes_)\n",
    "y_train = lb.inverse_transform(y_train, lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "\n",
    "matrix = confusion_matrix(y_train, y_pred, labels=lb.classes_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "sns.heatmap(matrix, annot=True, cmap='Greens', fmt='d', ax=ax)\n",
    "plt.title('Confusion Matrix for training dataset')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the errors in the plots\n",
    "\n",
    "np.seterr(all='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get convolutional layers\n",
    "\n",
    "layers = [model.get_layer('conv2d_1'), \n",
    "          model.get_layer('conv2d_2'),\n",
    "          model.get_layer('conv2d_3'),\n",
    "          model.get_layer('conv2d_4'),\n",
    "          model.get_layer('conv2d_5'),\n",
    "          model.get_layer('conv2d_6')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model which gives the outputs of the layers\n",
    "\n",
    "layer_outputs = [layer.output for layer in layers]\n",
    "activation_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the names of the layers\n",
    "\n",
    "layer_names = []\n",
    "for layer in layers:\n",
    "    layer_names.append(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function which will plot the convolutional filters\n",
    "\n",
    "def plot_convolutional_filters(img):\n",
    "    \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    activations = activation_model.predict(img)\n",
    "    images_per_row = 9\n",
    "    \n",
    "    for layer_name, layer_activation in zip(layer_names, activations): \n",
    "        n_features = layer_activation.shape[-1]\n",
    "        size = layer_activation.shape[1]\n",
    "        n_cols = n_features // images_per_row\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "        for col in range(n_cols): \n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0,\n",
    "                                                 :, :,\n",
    "                                                 col * images_per_row + row]\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                display_grid[col * size : (col + 1) * size,\n",
    "                             row * size : (row + 1) * size] = channel_image\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X_train[42500]\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convolutional_filters(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
